{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Objective- </b>\n",
    "\n",
    "In this assignment, you will create and train a convolutional network using our automatic differentiation framework. There are two major tasks:\n",
    "1. Implement a simple but useful convolutional layer within our automatic differentiation framework. The layer won't support padding and will only permit a stride of 1. Your implementation will not make use of the Toeplitz matrix (which converts convolution into a matrix multiplication). Instead, it will convolve the filter over the input tensor. With NumPy, this can be slow, so your implementation will make use of a just-in-time (JIT) NumPy acceleration library called Numba.\n",
    "2. Construct and train a convolutional network similar to LeNet, using our automatic differentiation framework, to classify digits. To keep training times low, the dataset you'll use is a subset of the MNIST dataset that includes only subsets of the digits 3, 7, 8, and 9 -- which tend to be near one another in the learned representation space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Files provided- </b>\n",
    "1. **functions.py** - Contains the definition of functions supported by auto-diff framework. No change is required in this file.\n",
    "2. **utils.py**      - Contains utilities for auto-diff framework. No change is required in this file.\n",
    "3. **tensor.py**    - Contains the Tensor wrapper class. Two additional functions have been added to the Tensor class, *conv2d and reshape*, you will provide a definition for these operations in the file conv_functions.py. No change is required in this file.\n",
    "4. **np_utils.py** - Contains an example for accelerated version of rot180 (i.e. np.rot90 applied twice). You may add additional helper functions or use the given function if it helps.\n",
    "\n",
    "<b> Files to be modified - </b>\n",
    "1. **conv_functions.py** - Contains the definition of Convolution2D and Reshape operations added to the Tensor class. The first major task is to implement these two classes. Please look into the file for additional details.\n",
    "2. **assignment_7.ipynb** - Contains unit tests for your implementation of Convolution2D and Reshape operations. Additionally you will implement a network similar to LeNet.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Notes for Task 1 </b>\n",
    "* You are free to implement the forward and backward pass for convolution operation as you see fit.\n",
    "* If you find that the implementation is time consuming, you can use Numba to accelerate it. More information about Numba can be found here - http://numba.pydata.org/\n",
    "    * Some key details on Numba :\n",
    "        * All you need to numba-fy your function is to add a decorator to it. Please refer the example_helper_func given in conv_functions.py.\n",
    "        * Numba doesn't understand the *self* argument, so ensure that your accelerated functions do not have *self* as an argument.\n",
    "        * While Numba supports most NumPy functions, some of them (that you might need, ex: np.pad, np.rot90) are not supported. Please refer https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html for more information.\n",
    "        * With Numba, it takes about 60-90 seconds to pass the unit tests.\n",
    "* Stride and Padding are defaulted to 1 and 0 respectively and are only included to keep an extensible interface, you won't use them in your implementation (unless you want to support arbitrary stride/padding)\n",
    "* In the unit tests, your implementation is tested against PyTorch's. Please refer https://pytorch.org/docs/stable/nn.html for documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Notes for Task 2 </b>\n",
    "* You will use the newly integrated conv2d layers to create a LeNet style network, The task is to classify a subset of MNIST digits. The dataset contains digits 3, 7, 8, 9 of size 1x21x21. It has 4k training examples and 1k validation examples.\n",
    "* You may use the following configuration for your LeNet style network - \n",
    "    * Kernel for first conv layer: number of filters = 2, kernel size = (1, 6, 6), ReLU activation\n",
    "    * Kernel for second conv layer: number of filters = 8, kernel size = (2, 6, 6), ReLU activation\n",
    "    * Out size for first fully connected layer = 100, ReLU activation\n",
    "    * Out size for output fully connected layer = 4, sigmoid activation\n",
    "    * MSE loss between one-hot encoded true labels and predictions.\n",
    "* You are free to use the entire dataset if you have enough compute, but are not required to do so. \n",
    "* The idea is to use simple, already implemented blocks to form the network, even if it might not be the best design choice (e.g. sigmoid instead of softmax at output, MSE loss instead of cross entropy loss, absence of pooling layers, etc.). You are free to add operations within the AD framework if you want to try out something new. Please share your tested implementation on Piazza if you do so!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the convolutional layer within your automatic differentiation framework with no padding and a fixed stride of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functions import Function\n",
    "import unittest\n",
    "import torch\n",
    "from tensor import Tensor\n",
    "import time\n",
    "from numba import jit\n",
    "import np_utils\n",
    "import copy\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "from conv_functions import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTests(unittest.TestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self._started_at = time.time()\n",
    "\n",
    "    def tearDown(self):\n",
    "        elapsed = time.time() - self._started_at\n",
    "        print('{} ({}s)'.format(self.id(), round(elapsed, 2)))\n",
    "\n",
    "    def test_forward_1(self):\n",
    "        a = np.random.rand(50, 1, 50, 50)\n",
    "        b = np.random.rand(20, 1, 2, 2)\n",
    "        # Implementation\n",
    "        result_1 = Tensor(a).conv2d(Tensor(b)).value\n",
    "        # Torch\n",
    "        result_2 = torch.nn.functional.conv2d(torch.tensor(a), torch.tensor(b), stride=1).numpy()\n",
    "\n",
    "        self.assertEqual(np.allclose(result_1, result_2), True)\n",
    "\n",
    "    def test_forward_2(self):\n",
    "        a = np.random.rand(50, 1, 28, 28)\n",
    "        b = np.random.rand(50, 1, 3, 4)\n",
    "        # Implementation\n",
    "        result_1 = Tensor(a).conv2d(Tensor(b)).value\n",
    "        # Torch\n",
    "        result_2 = torch.nn.functional.conv2d(torch.tensor(a), torch.tensor(b), stride=1).numpy()\n",
    "\n",
    "        self.assertEqual(np.allclose(result_1, result_2), True)\n",
    "\n",
    "    def test_forward_3(self):\n",
    "        a = np.random.rand(20, 3, 28, 30)\n",
    "        b = np.random.rand(50, 3, 4, 4)\n",
    "        # Implementation\n",
    "        result_1 = Tensor(a).conv2d(Tensor(b)).value\n",
    "        # Torch\n",
    "        result_2 = torch.nn.functional.conv2d(torch.tensor(a), torch.tensor(b), stride=1).numpy()\n",
    "\n",
    "        self.assertEqual(np.allclose(result_1, result_2), True)\n",
    "\n",
    "    def test_backward_1(self):\n",
    "        a = np.random.rand(50, 2, 30, 30)\n",
    "        b = np.random.rand(20, 2, 2, 2)\n",
    "        # Implementation\n",
    "        inp_1 = Tensor(a)\n",
    "        kernel_1 = Tensor(b)\n",
    "        res_1 = inp_1.conv2d(kernel_1)\n",
    "        mse_1 = res_1.sum()\n",
    "        mse_1.backward()\n",
    "        # Torch\n",
    "        inp_2 = torch.tensor(a, requires_grad=True)\n",
    "        kernel_2 = torch.tensor(b, requires_grad=True)\n",
    "        res_2 = torch.nn.functional.conv2d(inp_2, kernel_2, stride=1)\n",
    "        mse_2 = torch.sum(res_2)\n",
    "        mse_2.backward()\n",
    "\n",
    "        self.assertEqual(np.allclose(inp_1.grad, inp_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(kernel_1.grad, kernel_2.grad.numpy()), True)\n",
    "\n",
    "    def test_backward_2(self):\n",
    "        a = np.random.rand(3, 1, 3, 3)\n",
    "        b = np.random.rand(2, 1, 2, 2)\n",
    "        # Implementation\n",
    "        inp_1 = Tensor(a)\n",
    "        kernel_1 = Tensor(b)\n",
    "        res_1 = inp_1.conv2d(kernel_1)\n",
    "        y_1 = Tensor(np.ones_like(res_1.value))\n",
    "        mse_1 = (y_1 - res_1).pow(2).sum()\n",
    "        mse_1.backward()\n",
    "        # Torch\n",
    "        inp_2 = torch.tensor(a, requires_grad=True)\n",
    "        kernel_2 = torch.tensor(b, requires_grad=True)\n",
    "        res_2 = torch.nn.functional.conv2d(inp_2, kernel_2, stride=1)\n",
    "        y_2 = torch.tensor(np.ones_like(res_2.data))\n",
    "        mse_2 = torch.sum((y_2 - res_2) ** 2)\n",
    "        mse_2.backward()\n",
    "\n",
    "        self.assertEqual(np.allclose(inp_1.grad, inp_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(kernel_1.grad, kernel_2.grad.numpy()), True)\n",
    "\n",
    "    def test_backward_3(self):\n",
    "        a = np.random.rand(4, 3, 20, 20)\n",
    "        b = np.random.rand(10, 3, 3, 4)\n",
    "        # Implementation\n",
    "        inp_1 = Tensor(a)\n",
    "        kernel_1 = Tensor(b)\n",
    "        res_1 = inp_1.conv2d(kernel_1)\n",
    "        y_1 = Tensor(np.ones_like(res_1.value))\n",
    "        mse_1 = (y_1 - res_1).pow(2).sum()\n",
    "        mse_1.backward()\n",
    "        # Torch\n",
    "        inp_2 = torch.tensor(a, requires_grad=True)\n",
    "        kernel_2 = torch.tensor(b, requires_grad=True)\n",
    "        res_2 = torch.nn.functional.conv2d(inp_2, kernel_2, stride=1)\n",
    "        y_2 = torch.tensor(np.ones_like(res_2.data))\n",
    "        mse_2 = torch.sum((y_2 - res_2) ** 2)\n",
    "        mse_2.backward()\n",
    "\n",
    "        self.assertEqual(np.allclose(inp_1.grad, inp_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(kernel_1.grad, kernel_2.grad.numpy()), True)\n",
    "\n",
    "    def test_layers_4(self):\n",
    "        a = np.random.rand(2, 2, 8, 8)\n",
    "        b = np.random.rand(3, 2, 4, 4)\n",
    "        c = np.random.rand(4, 3, 2, 2)\n",
    "        # Implementation\n",
    "        inp_1 = Tensor(a)\n",
    "        kernel_1 = Tensor(b)\n",
    "        kernel_11 = Tensor(c)\n",
    "        res_1 = inp_1.conv2d(kernel_1)\n",
    "        res_11 = res_1.conv2d(kernel_11)\n",
    "        y_1 = Tensor(np.ones_like(res_11.value))\n",
    "        mse = (y_1 - res_11).pow(2).sum()\n",
    "        mse.backward()\n",
    "        # Torch\n",
    "        inp_2 = torch.tensor(a, requires_grad=True)\n",
    "        kernel_2 = torch.tensor(b, requires_grad=True)\n",
    "        kernel_22 = torch.tensor(c, requires_grad=True)\n",
    "        res_2 = torch.nn.functional.conv2d(inp_2, kernel_2, stride=1)\n",
    "        res_22 = torch.nn.functional.conv2d(res_2, kernel_22, stride=1)\n",
    "        y_2 = torch.tensor(np.ones_like(res_22.data))\n",
    "        mse = torch.sum((y_2 - res_22) ** 2)\n",
    "        mse.backward()\n",
    "\n",
    "        self.assertEqual(np.allclose(inp_1.grad, inp_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(kernel_1.grad, kernel_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(kernel_11.grad, kernel_22.grad.numpy()), True)\n",
    "\n",
    "    def test_time(self):\n",
    "        a = np.random.rand(100, 1, 28, 28)\n",
    "        b = np.random.rand(20, 1, 14, 14)\n",
    "        c = np.random.rand(30, 20, 7, 7)\n",
    "        # Implementation\n",
    "        inp_1 = Tensor(a)\n",
    "        kernel_1 = Tensor(b)\n",
    "        kernel_11 = Tensor(c)\n",
    "        res_1 = inp_1.conv2d(kernel_1)\n",
    "        res_11 = res_1.conv2d(kernel_11)\n",
    "        y_1 = Tensor(np.ones_like(res_11.value))\n",
    "        mse_1 = (y_1 - res_11).pow(2).sum()\n",
    "        mse_1.backward()\n",
    "        # Torch\n",
    "        inp_2 = torch.tensor(a, requires_grad=True)\n",
    "        kernel_2 = torch.tensor(b, requires_grad=True)\n",
    "        kernel_22 = torch.tensor(c, requires_grad=True)\n",
    "        res_2 = torch.nn.functional.conv2d(inp_2, kernel_2, stride=1)\n",
    "        res_22 = torch.nn.functional.conv2d(res_2, kernel_22, stride=1)\n",
    "        y_2 = torch.tensor(np.ones_like(res_22.data))\n",
    "        mse_2 = torch.sum((y_2 - res_22) ** 2)\n",
    "        mse_2.backward()\n",
    "\n",
    "        self.assertEqual(np.allclose(inp_1.grad, inp_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(kernel_1.grad, kernel_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(kernel_11.grad, kernel_22.grad.numpy()), True)\n",
    "\n",
    "    def test_reshape(self):\n",
    "        a = np.random.rand(2, 4, 3, 3)\n",
    "        b = np.random.rand(72, 1)\n",
    "        # Implementation\n",
    "        inp_1 = Tensor(a)\n",
    "        inp_11 = Tensor(b)\n",
    "        reshape_1 = inp_1.reshape(b.shape)\n",
    "        loss_1 = (inp_11 + reshape_1).sum()\n",
    "        loss_1.backward()\n",
    "        # Torch\n",
    "        inp_2 = torch.tensor(a, requires_grad=True)\n",
    "        inp_22 = torch.tensor(b, requires_grad=True)\n",
    "        reshape_2 = torch.sum(inp_2.view(b.shape) + inp_22)\n",
    "        reshape_2.backward()\n",
    "\n",
    "        self.assertEqual(np.allclose(inp_1.grad, inp_2.grad.numpy()), True)\n",
    "        self.assertEqual(np.allclose(inp_11.grad, inp_22.grad.numpy()), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a CNN similar to LeNet to classify digits in a reduced MNIST dataset, Plot the training error and validation accuracy against epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwork:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize convolutional and fully connected weights here.\n",
    "        Kaiming weight initialization works well for the model.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_in):\n",
    "        \"\"\"\n",
    "        Forward pass of the network.\n",
    "        :param input_in: Input tensor of size (batch_size x in_channels x height x width).\n",
    "        :return: output tensor (batch_size x out_size).\n",
    "        \"\"\"\n",
    "        return None\n",
    "\n",
    "    def update(self, lr):\n",
    "        \"\"\"\n",
    "        Update the weights of the network using SGD.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Reset gradients for the weights of the network.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X, y):\n",
    "    \"\"\"\n",
    "    Test the model\n",
    "    :param model: Trained ConvNetwork object.\n",
    "    :param X: Validation set inputs.\n",
    "    :param y: Validation set targets.\n",
    "    :return: Accuracy of model.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, y, X_valid, y_valid, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Train the model and validate it every few epochs.\n",
    "    :param model: ConvNetwork object.\n",
    "    :param X: Training set inputs.\n",
    "    :param y: Training set targets.\n",
    "    :param X_valid: Validation set inputs.\n",
    "    :param y_valid: Validation set targets.\n",
    "    :return: Training error for every epoch.\n",
    "    :return: Validation accuracy every few epochs.\n",
    "    \"\"\"\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_digit(x, label=None):\n",
    "    \"\"\"\n",
    "    Utility function to view the training data.\n",
    "    (courtesy - Chris Ketelsen)\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(x.reshape(21, 21), cmap='gray');\n",
    "    plt.xticks([]);\n",
    "    plt.yticks([]);\n",
    "    if label:\n",
    "        plt.xlabel(\"true: {}\".format(label), fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into training and validation sets.\n",
    "X_train, y_train, X_valid, y_valid = pickle.load(gzip.open(\"data/mnist21x21_3789_one_hot.pklz\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the training data.\n",
    "training_index = 5\n",
    "label_dict = dict({0: 3, 1: 7, 2: 8, 3: 9})\n",
    "view_digit(X_train[training_index], label_dict[np.argmax(y_train[training_index])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0s)\n"
     ]
    }
   ],
   "source": [
    "# Train and validate the network\n",
    "network = ConvNetwork()\n",
    "\n",
    "num_train = 500\n",
    "num_valid = 100\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "_started_at = time.time()\n",
    "train(network, X_train[:num_train], y_train[:num_train], X_valid[:num_valid], y_valid[:num_valid], epochs, batch_size)\n",
    "elapsed = time.time() - _started_at\n",
    "print('({}s)'.format(round(elapsed, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
